[parameters]
epoches=30
batch_size=6144
embed_size=32
layers=[128,64,32]
reg_gmf=1e-2
reg_mlp=1e-3
lr=0.001
neg_ratio=4
optimizer=Adam
# pointwise/pairwise
is_pairwise=False
loss_func=cross_entropy
init_method=xavier_uniform 
stddev=0.01
# pretrain
gmf_pretrain=./saved_model/GMF
mlp_pretrain=./saved_model/MLP